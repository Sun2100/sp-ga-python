{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneralAssembly Python Unit Lab\n",
    "\n",
    "In this lab, you will use Pandas and other Python libraries to generate and communicate business insights from a dataset.\n",
    "\n",
    "You will have the entire class period to complete the lab. At the end of class, you will share your final deliverable with your instructor for review. You may choose to work on the lab individually or with your classmates, but each person must turn in their own work.\n",
    "\n",
    "### Dataset Options\n",
    "\n",
    "Choose one of the three options below for your lab:\n",
    "\n",
    "\n",
    "| **Data Set** | **Problem Statement** |\n",
    "| :-- | :--| \n",
    "| **Option #1: [Grocery Sales](https://drive.google.com/drive/folders/1ee2aA6pphm6-54f2AT8Tv6U7h7nhIjnB?usp=sharing)** | A grocery sales company is looking for patterns in their sales data regarding regions, sales reps, and product categories. Conduct an analysis to surface any notable patterns, particularly related to sales results. |  \n",
    "| **Option #2: [Home Credit](https://drive.google.com/drive/folders/1MmI0NC4m0EJPbZ8UoICd1-xlXn59A0R7?usp=sharing)** | Home Credit is looking for patterns in their data regarding the default risk of consumer loans. Conduct an analysis to surface any notable patterns related to default risk. | \n",
    "| **Option #3: [College Board](https://drive.google.com/drive/folders/1oVT9IhblWOoIt4Gamg4gSOyECHKJaDjc?usp=sharing)** | A new format for the SAT was released in March 2016. As a consultant for the College Board — the company that administers the SAT — you are tracking statewide participation to recommend where to spend money to improve SAT participation rates. Conduct an analysis to make a recommendation on how the College Board can increase participation in a state of your choice. | \n",
    "\n",
    "### Deliverables\n",
    "\n",
    "No matter what dataset you choose, you will submit a Jupyter notebook containing:\n",
    "\n",
    "* Imported data, including at least two data frames and at least one combination of data frames via methods such as joining.\n",
    "* Functions for cleaning the data set, with explanations for how null values are being handled in each field.\n",
    "* At least two visualizations accompanied by textual descriptions of the business insights they communicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Grocery Sales\n",
    "\n",
    "Our goal is to analyze this dataset and explore for notable patterns, particularly related to sales results.  To do so, we will follow the given process:\n",
    "\n",
    "1. Look at the complete dataset and identify an approach.\n",
    "1. Clean the data with rationale-backed handling of null or missing values.\n",
    "1. Join the datasets together into a single dataframe.\n",
    "1. Analyze sales results and supply chain logistics in relation to other data points of your choosing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Look At The Data!\n",
    "\n",
    "By printing the first few columns of each dataset, we can see how they might be combined to open up opportunities for analysis.  To do this, we need to import libraries, load the datasets into variables, and print their heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%KEY</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Customer Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>GrossSales</th>\n",
       "      <th>Invoice Date</th>\n",
       "      <th>Invoice Number</th>\n",
       "      <th>Item Desc</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Order Number</th>\n",
       "      <th>Promised Delivery Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Sales Qty</th>\n",
       "      <th>Sales Rep Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3428</td>\n",
       "      <td>-513.15</td>\n",
       "      <td>10012226</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-573.3835</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>318960</td>\n",
       "      <td>Cutting Edge Sliced Ham</td>\n",
       "      <td>10696</td>\n",
       "      <td>-37.29</td>\n",
       "      <td>115785</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-550.44</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3429</td>\n",
       "      <td>-105.93</td>\n",
       "      <td>10012226</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-204.6638</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>318960</td>\n",
       "      <td>Washington Cranberry Juice</td>\n",
       "      <td>10009</td>\n",
       "      <td>-90.54</td>\n",
       "      <td>115785</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-196.47</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3430</td>\n",
       "      <td>-88.07</td>\n",
       "      <td>10012226</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-165.8016</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>318960</td>\n",
       "      <td>Moms Sliced Ham</td>\n",
       "      <td>10385</td>\n",
       "      <td>-71.10</td>\n",
       "      <td>115785</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-159.17</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3431</td>\n",
       "      <td>-43.12</td>\n",
       "      <td>10012226</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-118.3703</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>318960</td>\n",
       "      <td>Tip Top Lox</td>\n",
       "      <td>10215</td>\n",
       "      <td>-70.52</td>\n",
       "      <td>115785</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-113.64</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3432</td>\n",
       "      <td>-37.98</td>\n",
       "      <td>10012226</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-102.3319</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>318960</td>\n",
       "      <td>Just Right Beef Soup</td>\n",
       "      <td>10965</td>\n",
       "      <td>-60.26</td>\n",
       "      <td>115785</td>\n",
       "      <td>1/12/2012</td>\n",
       "      <td>-98.24</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   %KEY    Cost  Customer Number       Date  GrossSales Invoice Date  \\\n",
       "0  3428 -513.15         10012226  1/12/2012   -573.3835    1/12/2012   \n",
       "1  3429 -105.93         10012226  1/12/2012   -204.6638    1/12/2012   \n",
       "2  3430  -88.07         10012226  1/12/2012   -165.8016    1/12/2012   \n",
       "3  3431  -43.12         10012226  1/12/2012   -118.3703    1/12/2012   \n",
       "4  3432  -37.98         10012226  1/12/2012   -102.3319    1/12/2012   \n",
       "\n",
       "   Invoice Number                   Item Desc  Item Number  Margin  \\\n",
       "0          318960     Cutting Edge Sliced Ham        10696  -37.29   \n",
       "1          318960  Washington Cranberry Juice        10009  -90.54   \n",
       "2          318960             Moms Sliced Ham        10385  -71.10   \n",
       "3          318960                 Tip Top Lox        10215  -70.52   \n",
       "4          318960        Just Right Beef Soup        10965  -60.26   \n",
       "\n",
       "   Order Number Promised Delivery Date   Sales  Sales Qty  Sales Rep Number  \n",
       "0        115785              1/12/2012 -550.44       -1.0               180  \n",
       "1        115785              1/12/2012 -196.47       -2.0               180  \n",
       "2        115785              1/12/2012 -159.17       -3.0               180  \n",
       "3        115785              1/12/2012 -113.64       -1.0               180  \n",
       "4        115785              1/12/2012  -98.24       -1.0               180  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display plots in the Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# import datasets (you may have to change the directory/file names)\n",
    "# note the encoding option to deal with a read error!\n",
    "cities = pd.read_csv('cities.csv', encoding = 'ISO-8859-1', engine='python')\n",
    "customers = pd.read_csv('customers.csv', encoding = 'ISO-8859-1', engine='python')\n",
    "item_master = pd.read_csv('item_master.csv', encoding = 'ISO-8859-1', engine='python')\n",
    "sales = pd.read_csv('sales.csv', encoding = 'ISO-8859-1', engine='python')\n",
    "sales_rep = pd.read_csv('sales_rep.csv', encoding = 'ISO-8859-1', engine='python')\n",
    "\n",
    "# as an example, print the first rows of sales using the head() method\n",
    "sales.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sales` dataset has 15 columns, as shown above.  While it contains a lot of information, we can use the other datasets to add detail to these rows.  In order to see some possible connections, it may be helpful to visualize the columns in each dataset.  I have constructed the following un-connected diagram:\n",
    "<img src='./GroceryColumns.png'>\n",
    "\n",
    "From this, we may propose some connections, as shown in the following schema diagram:\n",
    "<img src='./GrocerySchema.png'>\n",
    "\n",
    "The above connections leverage the following links:\n",
    "1. Geographic information from the `City Code` column in `cities`, connected through the `customers` dataset.\n",
    "1. Product information from the `item_master` dataset, using the shared `Item Number` column.\n",
    "1. Managerial information from the `sales_rep` dataset, leveraging the `Sales Rep ID` and `Sales Rep Number` columns\n",
    "\n",
    "Already, some initial questions may be formulated:\n",
    "\n",
    "1. How do total sales vary across geographic regions?\n",
    "1. What item categories comprise the bulk of sales volume?\n",
    "1. What managers are linked to salespeople with the highest totals?\n",
    "\n",
    "In order to conduct analysis and produce some potential answers, we need to clean and join the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Yokohama</td>\n",
       "      <td>95</td>\n",
       "      <td>Japan</td>\n",
       "      <td>35.455592</td>\n",
       "      <td>139.572196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City  City Code Region   Latitude   Longitude Desc\n",
       "94  Yokohama         95  Japan  35.455592  139.572196  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities[cities[\"Desc\"].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6/26/2014'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[\"Date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean The Data!\n",
    "\n",
    "For each dataset, we will:\n",
    "1. Identify columns with null values by printing null totals.\n",
    "2. inspect columns with null values to determine what kind of data they contain.\n",
    "3. Decide how to address the nulls based on what replacement method is most appropriate.\n",
    "4. Check that date columns are actually dates, and convert them if not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values by Column - 'cities' Dataset\n",
      "Desc         1\n",
      "City         0\n",
      "City Code    0\n",
      "Region       0\n",
      "Latitude     0\n",
      "Longitude    0\n",
      "dtype: int64 \n",
      "\n",
      "Null Values by Column - 'customers' Dataset\n",
      "Customer           0\n",
      "Customer Number    0\n",
      "City Code          0\n",
      "dtype: int64 \n",
      "\n",
      "Null Values by Column - 'item_master' Dataset\n",
      "Item Number          0\n",
      "Product Group        0\n",
      "Product Line         0\n",
      "Product Sub Group    0\n",
      "Product Type         0\n",
      "dtype: int64 \n",
      "\n",
      "Null Values by Column - 'sales' Dataset\n",
      "%KEY                      0\n",
      "Cost                      0\n",
      "Customer Number           0\n",
      "Date                      0\n",
      "GrossSales                0\n",
      "Invoice Date              0\n",
      "Invoice Number            0\n",
      "Item Desc                 0\n",
      "Item Number               0\n",
      "Margin                    0\n",
      "Order Number              0\n",
      "Promised Delivery Date    0\n",
      "Sales                     0\n",
      "Sales Qty                 0\n",
      "Sales Rep Number          0\n",
      "dtype: int64 \n",
      "\n",
      "Null Values by Column - 'sales_rep' Dataset\n",
      "Sales Rep Name3    25\n",
      "Sales Rep Name2     5\n",
      "Manager             0\n",
      "Manager Number      0\n",
      "Path                0\n",
      "Sales Rep Name      0\n",
      "Sales Rep Name1     0\n",
      "Sales Rep ID        0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the number of null values, by column, in each dataset\n",
    "print('Null Values by Column - \\'cities\\' Dataset')\n",
    "print(cities.isnull().sum().sort_values(ascending=False), '\\n')\n",
    "\n",
    "#1. Identify columns with null values by printing null totals.\n",
    "    #cities.isnull().sum()\n",
    "#2. inspect columns with null values to determine what kind of data they contain.\n",
    "    #cities[cities[\"Desc\"].isnull() == True]\n",
    "#3. Decide how to address the nulls based on what replacement method is most appropriate.\n",
    "########################################################################################################\n",
    "    #in this case, Desc should stands for description, hence, the null data should describe the location\n",
    "    #Yokohama, Japan, lat 35.455592 and long 139.572196 \n",
    "    #https://www.gps-coordinates.net/\n",
    "    #unnamed road, Hodogaya Ward, Yokohama, Kanagawa Prefecture 231-0017, Japan\n",
    "    #TODO ANS: \"Hodogaya Ward,Yokohama City,Kanagawa Prefecture,JP\"\n",
    "########################################################################################################\n",
    "#4. Check that date columns are actually dates, and convert them if not!\n",
    "    #check in sales.csv \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print('Null Values by Column - \\'customers\\' Dataset')\n",
    "print(customers.isnull().sum().sort_values(ascending=False), '\\n')\n",
    "\n",
    "print('Null Values by Column - \\'item_master\\' Dataset')\n",
    "print(item_master.isnull().sum().sort_values(ascending=False), '\\n')\n",
    "\n",
    "print('Null Values by Column - \\'sales\\' Dataset')\n",
    "print(sales.isnull().sum().sort_values(ascending=False), '\\n')\n",
    "\n",
    "print('Null Values by Column - \\'sales_rep\\' Dataset')\n",
    "print(sales_rep.isnull().sum().sort_values(ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales Rep Name3    25\n",
      "Sales Rep Name2     5\n",
      "Manager             0\n",
      "Manager Number      0\n",
      "Path                0\n",
      "Sales Rep Name      0\n",
      "Sales Rep Name1     0\n",
      "Sales Rep ID        0\n",
      "dtype: int64 \n",
      "\n",
      "sum of null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Manager             0\n",
       "Manager Number      0\n",
       "Path                0\n",
       "Sales Rep Name      0\n",
       "Sales Rep Name1     0\n",
       "Sales Rep Name2     5\n",
       "Sales Rep Name3    25\n",
       "Sales Rep ID        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sales_rep.isnull().sum().sort_values(ascending=False), '\\n')\n",
    "print(\"*****sum of null******\")\n",
    "sales_rep.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This dataset appears to have zero nulls, for our purposes.\n",
    "\n",
    "The `Desc` column of the `cities` is a long-form description of the city, which is not necessary for our analysis.  The `sales_rep` dataset's nulls are all in the `Sales Rep Name2` and `Sales Rep Name3` columns, which indicates that there are some rows where only one salesperson was involved.\n",
    "\n",
    "For example, let's investigate further by printing out rows, even though no replacement is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  City Code Region   Latitude   Longitude Desc\n",
      "94  Yokohama         95  Japan  35.455592  139.572196  NaN \n",
      "\n",
      "           Manager  Manager Number                             Path  \\\n",
      "0     Amanda Honda             104        Amanda Honda-Amalia Craig   \n",
      "1     Amanda Honda             104          Amanda Honda-Cart Lynch   \n",
      "2     Amanda Honda             104      Amanda Honda-Molly McKenzie   \n",
      "3     Amanda Honda             104         Amanda Honda-Sheila Hein   \n",
      "4    Brenda Gibson             109     Brenda Gibson-Dennis Johnson   \n",
      "5    Brenda Gibson             109        Brenda Gibson-Ken Roberts   \n",
      "6    Brenda Gibson             109         Brenda Gibson-Robert Kim   \n",
      "7    Brenda Gibson             109     Brenda Gibson-William Fisher   \n",
      "21       John Greg             134          John Greg-David Laychak   \n",
      "22       John Greg             134          John Greg-Kathy Clinton   \n",
      "23       John Greg             134          John Greg-Sandra Barone   \n",
      "24       John Greg             134       John Greg-Viginia Mountain   \n",
      "41  Samantha Allen             169       Samantha Allen-Brad Taylor   \n",
      "42  Samantha Allen             169     Samantha Allen-Karl Anderson   \n",
      "43  Samantha Allen             169     Samantha Allen-Odessa Morris   \n",
      "44  Samantha Allen             169  Samantha Allen-Stephanie Reagan   \n",
      "52    Stewart Wind             181      Stewart Wind-Carolyn Halmon   \n",
      "53    Stewart Wind             181          Stewart Wind-John Davis   \n",
      "54    Stewart Wind             181    Stewart Wind-Micheal Williams   \n",
      "55    Stewart Wind             181     Stewart Wind-Ronald Golinski   \n",
      "59    Amanda Honda             104                     Amanda Honda   \n",
      "60   Brenda Gibson             109                    Brenda Gibson   \n",
      "61       John Greg             134                        John Greg   \n",
      "62  Samantha Allen             169                   Samantha Allen   \n",
      "63    Stewart Wind             181                     Stewart Wind   \n",
      "\n",
      "      Sales Rep Name Sales Rep Name1   Sales Rep Name2 Sales Rep Name3  \\\n",
      "0       Amalia Craig    Amanda Honda      Amalia Craig             NaN   \n",
      "1         Cart Lynch    Amanda Honda        Cart Lynch             NaN   \n",
      "2     Molly McKenzie    Amanda Honda    Molly McKenzie             NaN   \n",
      "3        Sheila Hein    Amanda Honda       Sheila Hein             NaN   \n",
      "4     Dennis Johnson   Brenda Gibson    Dennis Johnson             NaN   \n",
      "5        Ken Roberts   Brenda Gibson       Ken Roberts             NaN   \n",
      "6         Robert Kim   Brenda Gibson        Robert Kim             NaN   \n",
      "7     William Fisher   Brenda Gibson    William Fisher             NaN   \n",
      "21     David Laychak       John Greg     David Laychak             NaN   \n",
      "22     Kathy Clinton       John Greg     Kathy Clinton             NaN   \n",
      "23     Sandra Barone       John Greg     Sandra Barone             NaN   \n",
      "24  Viginia Mountain       John Greg  Viginia Mountain             NaN   \n",
      "41       Brad Taylor  Samantha Allen       Brad Taylor             NaN   \n",
      "42     Karl Anderson  Samantha Allen     Karl Anderson             NaN   \n",
      "43     Odessa Morris  Samantha Allen     Odessa Morris             NaN   \n",
      "44  Stephanie Reagan  Samantha Allen  Stephanie Reagan             NaN   \n",
      "52    Carolyn Halmon    Stewart Wind    Carolyn Halmon             NaN   \n",
      "53        John Davis    Stewart Wind        John Davis             NaN   \n",
      "54  Micheal Williams    Stewart Wind  Micheal Williams             NaN   \n",
      "55   Ronald Golinski    Stewart Wind   Ronald Golinski             NaN   \n",
      "59      Amanda Honda    Amanda Honda               NaN             NaN   \n",
      "60     Brenda Gibson   Brenda Gibson               NaN             NaN   \n",
      "61         John Greg       John Greg               NaN             NaN   \n",
      "62    Samantha Allen  Samantha Allen               NaN             NaN   \n",
      "63      Stewart Wind    Stewart Wind               NaN             NaN   \n",
      "\n",
      "    Sales Rep ID  \n",
      "0            103  \n",
      "1            112  \n",
      "2            159  \n",
      "3            176  \n",
      "4            121  \n",
      "5            145  \n",
      "6            163  \n",
      "7            185  \n",
      "21           118  \n",
      "22           144  \n",
      "23           170  \n",
      "24           184  \n",
      "41           108  \n",
      "42           143  \n",
      "43           160  \n",
      "44           179  \n",
      "52           111  \n",
      "53           132  \n",
      "54           157  \n",
      "55           166  \n",
      "59           104  \n",
      "60           109  \n",
      "61           134  \n",
      "62           169  \n",
      "63           181  \n"
     ]
    }
   ],
   "source": [
    "# print out the rows in the 'cities' dataset where `Desc` is null\n",
    "cities_null_mask = cities[\"Desc\"].isnull()\n",
    "print(cities[cities_null_mask], '\\n')\n",
    "\n",
    "# print out the null rows in the 'sales_rep' dataset where `Sales Rep Name2` or `Sales Rep Name3` is Null\n",
    "sales_rep_null_mask = sales_rep[\"Sales Rep Name2\"].isnull() | sales_rep[\"Sales Rep Name3\"].isnull()\n",
    "print(sales_rep[sales_rep_null_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96466 entries, 0 to 96465\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   %KEY                    96466 non-null  int64  \n",
      " 1   Cost                    96466 non-null  float64\n",
      " 2   Customer Number         96466 non-null  int64  \n",
      " 3   Date                    96466 non-null  object \n",
      " 4   GrossSales              96466 non-null  float64\n",
      " 5   Invoice Date            96466 non-null  object \n",
      " 6   Invoice Number          96466 non-null  int64  \n",
      " 7   Item Desc               96466 non-null  object \n",
      " 8   Item Number             96466 non-null  int64  \n",
      " 9   Margin                  96466 non-null  float64\n",
      " 10  Order Number            96466 non-null  int64  \n",
      " 11  Promised Delivery Date  96466 non-null  object \n",
      " 12  Sales                   96466 non-null  float64\n",
      " 13  Sales Qty               96466 non-null  float64\n",
      " 14  Sales Rep Number        96466 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(4)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# get information about datatypes\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `Date`, `Invoice Date`, `Item Desc`, and `Promised Delivery Date` columns are **objects**, not dates.  We don't need the `Item Desc` column, and will choose the `Date` column as our only date column for this analysis.\n",
    "\n",
    "So, we will convert the `Date` column to datetime and drop the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96466 entries, 0 to 96465\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   %KEY              96466 non-null  int64         \n",
      " 1   Cost              96466 non-null  float64       \n",
      " 2   Customer Number   96466 non-null  int64         \n",
      " 3   Date              96466 non-null  datetime64[ns]\n",
      " 4   GrossSales        96466 non-null  float64       \n",
      " 5   Invoice Number    96466 non-null  int64         \n",
      " 6   Item Number       96466 non-null  int64         \n",
      " 7   Margin            96466 non-null  float64       \n",
      " 8   Order Number      96466 non-null  int64         \n",
      " 9   Sales             96466 non-null  float64       \n",
      " 10  Sales Qty         96466 non-null  float64       \n",
      " 11  Sales Rep Number  96466 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(6)\n",
      "memory usage: 8.8 MB\n"
     ]
    }
   ],
   "source": [
    "# convert the `Date` column to datetime, inferring the format\n",
    "sales['Date'] = pd.to_datetime(sales['Date'], format= \"%m/%d/%Y\")\n",
    "\n",
    "# drop the irrelevant columns\n",
    "    #we want to drop Invoice Date, Item Desc, and Promised Delivery Date column hence, axis is 1 \n",
    "sales.drop(\"Invoice Date\", axis = 1, inplace = True)\n",
    "sales.drop(\"Item Desc\", axis = 1, inplace = True)\n",
    "sales.drop(\"Promised Delivery Date\", axis = 1, inplace = True)\n",
    "\n",
    "#OR\n",
    "#sales.drop([‘Invoice Date’, ‘Item Desc’, ‘Promised Delivery Date’], axis=1, inplace=True)\n",
    "\n",
    "# get information about the new dataframe to confirm success\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%KEY</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Customer Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>GrossSales</th>\n",
       "      <th>Invoice Number</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Order Number</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Sales Qty</th>\n",
       "      <th>Sales Rep Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3428</td>\n",
       "      <td>-513.15</td>\n",
       "      <td>10012226</td>\n",
       "      <td>2012-01-12</td>\n",
       "      <td>-573.3835</td>\n",
       "      <td>318960</td>\n",
       "      <td>10696</td>\n",
       "      <td>-37.29</td>\n",
       "      <td>115785</td>\n",
       "      <td>-550.44</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3429</td>\n",
       "      <td>-105.93</td>\n",
       "      <td>10012226</td>\n",
       "      <td>2012-01-12</td>\n",
       "      <td>-204.6638</td>\n",
       "      <td>318960</td>\n",
       "      <td>10009</td>\n",
       "      <td>-90.54</td>\n",
       "      <td>115785</td>\n",
       "      <td>-196.47</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3430</td>\n",
       "      <td>-88.07</td>\n",
       "      <td>10012226</td>\n",
       "      <td>2012-01-12</td>\n",
       "      <td>-165.8016</td>\n",
       "      <td>318960</td>\n",
       "      <td>10385</td>\n",
       "      <td>-71.10</td>\n",
       "      <td>115785</td>\n",
       "      <td>-159.17</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3431</td>\n",
       "      <td>-43.12</td>\n",
       "      <td>10012226</td>\n",
       "      <td>2012-01-12</td>\n",
       "      <td>-118.3703</td>\n",
       "      <td>318960</td>\n",
       "      <td>10215</td>\n",
       "      <td>-70.52</td>\n",
       "      <td>115785</td>\n",
       "      <td>-113.64</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3432</td>\n",
       "      <td>-37.98</td>\n",
       "      <td>10012226</td>\n",
       "      <td>2012-01-12</td>\n",
       "      <td>-102.3319</td>\n",
       "      <td>318960</td>\n",
       "      <td>10965</td>\n",
       "      <td>-60.26</td>\n",
       "      <td>115785</td>\n",
       "      <td>-98.24</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   %KEY    Cost  Customer Number       Date  GrossSales  Invoice Number  \\\n",
       "0  3428 -513.15         10012226 2012-01-12   -573.3835          318960   \n",
       "1  3429 -105.93         10012226 2012-01-12   -204.6638          318960   \n",
       "2  3430  -88.07         10012226 2012-01-12   -165.8016          318960   \n",
       "3  3431  -43.12         10012226 2012-01-12   -118.3703          318960   \n",
       "4  3432  -37.98         10012226 2012-01-12   -102.3319          318960   \n",
       "\n",
       "   Item Number  Margin  Order Number   Sales  Sales Qty  Sales Rep Number  \n",
       "0        10696  -37.29        115785 -550.44       -1.0               180  \n",
       "1        10009  -90.54        115785 -196.47       -2.0               180  \n",
       "2        10385  -71.10        115785 -159.17       -3.0               180  \n",
       "3        10215  -70.52        115785 -113.64       -1.0               180  \n",
       "4        10965  -60.26        115785  -98.24       -1.0               180  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Join The Datasets!\n",
    "\n",
    "As a reminder, here's the schema diagram from step 1.\n",
    "<img src='./GrocerySchema.png'>\n",
    "We'll use joins in Pandas to connect the datasets into one larger set.  Note that we don't have to merge the tables in their entirety, and in fact it may be advantageous to select specific columns in order to save memory.  We can use the initial questions we proposed earlier to motivate our column selection:\n",
    "\n",
    "1. How do total sales vary across geographic regions?\n",
    "1. What item categories comprise the bulk of sales volume?\n",
    "1. What managers are linked to salespeople with the highest totals?\n",
    "\n",
    "So, we'll join the following columns from each dataset into the `sales` dataset, in steps:\n",
    "\n",
    "1. `cities` (`City`, `Region`) into `customers`\n",
    "2. `customers` (`Customer`, `City`, `Region`) into `sales`\n",
    "3. `item_master` (`Product Group`) into `sales`\n",
    "4. `sales_rep` (`Manager`) into `sales`\n",
    "\n",
    "Note that the shared column must be included in the list, otherwise the join will have no matches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Customer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/sun/Desktop/python-15/lab2/Data Analysis Starter Data/python-lab-data-grocery-sales/GeneralAssembly Python Unit Lab - Option 1.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=1'>2</a>\u001b[0m customers_cities \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(customers,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=2'>3</a>\u001b[0m                             cities[[\u001b[39m'\u001b[39m\u001b[39mCity Code\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRegion\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=3'>4</a>\u001b[0m                             how \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=4'>5</a>\u001b[0m                             left_on \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCity Code\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=5'>6</a>\u001b[0m                             right_on \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCity Code\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=8'>9</a>\u001b[0m \u001b[39m# join `customers_cities`, `item_master`, and `sales_rep` into `sales` using three successive joins\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=9'>10</a>\u001b[0m sales_with_cities \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(sales,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=10'>11</a>\u001b[0m                         customers_cities[[\u001b[39m'\u001b[39;49m\u001b[39mCustomer Number\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCustomer\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mCity\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mRegion\u001b[39;49m\u001b[39m'\u001b[39;49m]],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=11'>12</a>\u001b[0m                         how \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=12'>13</a>\u001b[0m                         left_on \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mCustomer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=13'>14</a>\u001b[0m                         right_on \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mCustomer\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=15'>16</a>\u001b[0m \u001b[39m#sales_with_items = pd.merge(sales_with_cities,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=16'>17</a>\u001b[0m \u001b[39m#                            item_master[['Item Number', 'Product Group']],\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=17'>18</a>\u001b[0m \u001b[39m#                        how = ____,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=27'>28</a>\u001b[0m \u001b[39m# print the head to check for a proper join\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=28'>29</a>\u001b[0m \u001b[39m#sales_final.head()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sun/Desktop/python-15/lab2/Data%20Analysis%20Starter%20Data/python-lab-data-grocery-sales/GeneralAssembly%20Python%20Unit%20Lab%20-%20Option%201.ipynb#ch0000013?line=29'>30</a>\u001b[0m customers_cities\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    108\u001b[0m         left,\n\u001b[1;32m    109\u001b[0m         right,\n\u001b[1;32m    110\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    111\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    112\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    113\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    114\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    115\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    116\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    117\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    118\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    119\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    120\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    121\u001b[0m     )\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[1;32m    695\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    696\u001b[0m (\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[1;32m    699\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[0;32m--> 700\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[1;32m    702\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1110\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(rk)\n\u001b[1;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m lk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     left_keys\u001b[39m.\u001b[39mappend(left\u001b[39m.\u001b[39;49m_get_label_or_level_values(lk))\n\u001b[1;32m   1111\u001b[0m     join_names\u001b[39m.\u001b[39mappend(lk)\n\u001b[1;32m   1112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[39m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mget_level_values(key)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1839\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1842\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Customer'"
     ]
    }
   ],
   "source": [
    "# merge customers and cities on the shared `City Code` column\n",
    "customers_cities = pd.merge(customers,\n",
    "                            cities[['City Code', 'City', 'Region']],\n",
    "                            how = \"left\",\n",
    "                            left_on = \"City Code\",\n",
    "                            right_on = \"City Code\")\n",
    "                            #or\n",
    "                            #on = \"City Code\"\n",
    "                            \n",
    "\n",
    "# join `customers_cities`, `item_master`, and `sales_rep` into `sales` using three successive joins\n",
    "sales_with_cities = pd.merge(sales,\n",
    "                        customers_cities[['Customer Number', 'Customer', 'City', 'Region']],\n",
    "                        how = \"right\",\n",
    "                        left_on = \"Customer\",\n",
    "                        right_on = \"Customer\")\n",
    "\n",
    "#sales_with_items = pd.merge(sales_with_cities,\n",
    "#                            item_master[['Item Number', 'Product Group']],\n",
    "#                        how = ____,\n",
    "#                        left_on = ____,\n",
    "#                        right_on = ____)\n",
    "\n",
    "#sales_final = pd.merge(sales_with_items,\n",
    "#                       sales_rep[['Sales Rep ID', 'Manager']],\n",
    "#                        how = ____,\n",
    "#                        left_on = ____,\n",
    "#                        right_on = ____)\n",
    "\n",
    "# print the head to check for a proper join\n",
    "#sales_final.head()\n",
    "customers_cities.head()\n",
    "#sales_with_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conduct Analysis!\n",
    "\n",
    "Here are the columns in our final dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in sales_final.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use Pandas' groupby() method to segment and analyze the data in accordance with our three analysis questions:\n",
    "\n",
    "1. How do total sales vary across geographic regions?\n",
    "1. What item categories comprise the bulk of sales volume?\n",
    "1. What managers are linked to salespeople with the highest totals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales by geographic region\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "grouped_data = sales_final.groupby(____).____.sort_values('Sales', ascending = False)['Sales']\n",
    "grouped_data.plot(ax = ax, kind = ____)\n",
    "plt.title('Total Sales ($) By Region')\n",
    "\n",
    "# regional sales over time\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "____\n",
    "plt.title('Annual Sales ($) By Region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales by product group\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "grouped_data = sales_final.groupby(____).____.sort_values('Sales', ascending = False)['Sales']\n",
    "grouped_data.plot(ax = ax, kind = 'bar')\n",
    "plt.title('Total Sales ($) By Product Group')\n",
    "\n",
    "# product group sales over time\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "____\n",
    "plt.title('Annual Sales ($) By Product Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sales by manager\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "____\n",
    "plt.title('Total Sales ($) By Manager')\n",
    "\n",
    "# sales per manager over time\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "____\n",
    "plt.title('Annual Sales ($) By Manager')\n",
    "\n",
    "# sales per manager in the USA\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "____\n",
    "plt.title('Annual USA Sales ($) By Manager in the USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, what conclusions or hypothesis can we draw from these initial analyses?\n",
    "\n",
    "1. The USA and UK comprise the vast majority of sales, but Japan's share of the total appears to have been increasing during the first part of 2014.\n",
    "\n",
    "1. Produce, Canned Products, and Deli are the top three product categories, by far.  In 2014, the margin between Produce and Canned Products shrank such that Canned Products could be projected to overtake the number one spot by the end of the year.\n",
    "\n",
    "1. Baking Goods look to be increasing their share of sales significantly, though they are still a much smaller proportion of overall sales.\n",
    "\n",
    "1. Some managers oversee significantly more sales than others, but it is difficult to compare performance between regions; John Greg, in particular, was a very strong performer over all three years, but appears to have a much larger USA proportion of overall sales in 2013 than in 2012 or 2014.\n",
    "\n",
    "#### Some additional exploration into the dataset could be fruitful.  Namely:\n",
    "\n",
    "1. What proportion of a managers' salespeople are dedicated to each region, each year?  We could use this to project expected sales, and compare performance of salespeople from one manager to another in an attempt to infer managerial performance.\n",
    "\n",
    "1. Are some individual products growing more year-over-year than others?  A breakout view of all products would be a lot of data to parse visually, but could reveal an interesting trend.\n",
    "\n",
    "#### There are also opportunities for prediction here, using Python packages such as SciKit-Learn:\n",
    "\n",
    "1. Using historical sales data by category, predict the remainder of sales in 2014 in order to compare the three years in the dataset more directly.\n",
    "\n",
    "2. Quantify the mean and variance of sales by salesperson, manager, or product.  Which are most or least volatile?\n",
    "\n",
    "3. If the company were to invest more into an existing product line, which would be most worthy?  Forecasting demand would facilitate such a decision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0d70ec63e48daca6a80a8f89659f2083bfc1275bfb9d7f3c65e2756bbb00474"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
